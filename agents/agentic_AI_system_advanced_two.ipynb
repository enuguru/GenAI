{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai duckduckgo-search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwhXUPNj4qiA",
        "outputId": "75dbc00e-071b-49f1-a880-de3bdcd3f7b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.70.0)\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-8.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.51)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.24)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.1)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.1.8)\n",
            "Collecting primp>=0.14.0 (from duckduckgo-search)\n",
            "  Downloading primp-0.14.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Downloading duckduckgo_search-8.0.0-py3-none-any.whl (18 kB)\n",
            "Downloading primp-0.14.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: primp, duckduckgo-search\n",
            "Successfully installed duckduckgo-search-8.0.0 primp-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxnKyLJc4uXe",
        "outputId": "e4aca6c3-5a72-40e8-c528-646283a8d339"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.51)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.24)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (2.11.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (4.13.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.4.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.21 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.agents import Tool\n",
        "from duckduckgo_search import DDGS\n",
        "import time"
      ],
      "metadata": {
        "id": "JmAFx4rS4pOv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SETUP OPENAI KEY ---\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"  # Replace with your real API key"
      ],
      "metadata": {
        "id": "df3sXtrS47N4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Tj8bKyh4jyl",
        "outputId": "c47b6d23-36fd-49cb-f809-8876cdf643a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-89a70addc3e3>:22: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Define the Tools ---\n",
        "\n",
        "def web_search(query: str) -> str:\n",
        "    with DDGS() as ddgs:\n",
        "        results = ddgs.text(query, max_results=2)\n",
        "        return \"\\n\".join([r[\"body\"] for r in results])\n",
        "\n",
        "def calculator(expression: str) -> str:\n",
        "    try:\n",
        "        result = eval(expression, {\"__builtins__\": {}})\n",
        "        return str(result)\n",
        "    except Exception as e:\n",
        "        return f\"Error calculating: {e}\"\n",
        "\n",
        "# -- Tools List --\n",
        "tools = {\n",
        "    \"search\": web_search,\n",
        "    \"calculate\": calculator\n",
        "}\n",
        "\n",
        "# --- Define the LLM ---\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0.3,\n",
        "    model_name=\"gpt-3.5-turbo\"\n",
        ")\n",
        "\n",
        "# --- Memory ---\n",
        "memory = []\n",
        "\n",
        "# --- Core Functions ---\n",
        "\n",
        "def create_subtasks(goal: str) -> list:\n",
        "    \"\"\"Use LLM to break down the big goal into small tasks.\"\"\"\n",
        "    prompt = f\"Break down the following goal into 3 to 5 clear subtasks:\\nGoal: {goal}\"\n",
        "    subtasks = llm.predict(prompt)\n",
        "    return [task.strip(\"- \").strip() for task in subtasks.split(\"\\n\") if task.strip()]\n",
        "\n",
        "def decide_tool(task: str) -> str:\n",
        "    \"\"\"Simple tool selector based on task.\"\"\"\n",
        "    math_keywords = ['+', '-', '*', '/', 'plus', 'minus', 'divide', 'multiply', '**']\n",
        "    if any(word in task.lower() for word in math_keywords):\n",
        "        return \"calculate\"\n",
        "    else:\n",
        "        return \"search\"\n",
        "\n",
        "def execute_task(task: str, tool_name: str) -> str:\n",
        "    \"\"\"Execute the selected tool.\"\"\"\n",
        "    tool_func = tools.get(tool_name)\n",
        "    if tool_func:\n",
        "        return tool_func(task)\n",
        "    else:\n",
        "        return \"No appropriate tool found.\"\n",
        "\n",
        "def reflect_and_improve():\n",
        "    \"\"\"Basic Reflection on what was done.\"\"\"\n",
        "    return \"I have reflected on past actions and learned better task execution sequencing.\"\n",
        "\n",
        "# --- Main Agent Loop ---\n",
        "\n",
        "def autonomous_agent(goal: str, max_cycles=5):\n",
        "    print(\"\\nüöÄ Starting Autonomous Agent for Goal:\", goal)\n",
        "    steps_completed = 0\n",
        "\n",
        "    # Step 1: Break Goal into Subtasks\n",
        "    subtasks = create_subtasks(goal)\n",
        "    print(\"\\nüìã Planned Subtasks:\")\n",
        "    for idx, subtask in enumerate(subtasks):\n",
        "        print(f\"{idx+1}. {subtask}\")\n",
        "\n",
        "    # Step 2: Execute Subtasks\n",
        "    for subtask in subtasks:\n",
        "        if steps_completed >= max_cycles:\n",
        "            print(\"\\n‚è∞ Max cycles reached, stopping.\")\n",
        "            break\n",
        "\n",
        "        print(f\"\\nüîé Working on Subtask: {subtask}\")\n",
        "\n",
        "        tool_name = decide_tool(subtask)\n",
        "        print(f\"üõ† Using Tool: {tool_name}\")\n",
        "\n",
        "        result = execute_task(subtask, tool_name)\n",
        "        print(f\"‚úÖ Result: {result}\")\n",
        "\n",
        "        # Save memory\n",
        "        memory.append({\"subtask\": subtask, \"tool\": tool_name, \"result\": result})\n",
        "        steps_completed += 1\n",
        "\n",
        "        # Simulate thinking time\n",
        "        time.sleep(1)\n",
        "\n",
        "    # Step 3: Reflection\n",
        "    print(\"\\nüß† Reflecting on session...\")\n",
        "    reflection = reflect_and_improve()\n",
        "    memory.append({\"reflection\": reflection})\n",
        "\n",
        "    # Step 4: Summary\n",
        "    print(\"\\nüìö Final Summary of Actions:\")\n",
        "    for m in memory:\n",
        "        print(m)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Run Agent ---\n",
        "if __name__ == \"__main__\":\n",
        "    user_goal = input(\"\\nüéØ Enter your BIG GOAL: \")\n",
        "    autonomous_agent(user_goal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bEBUrha4mvB",
        "outputId": "dca0c93f-1db0-4830-d55e-613c568b522c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéØ Enter your BIG GOAL: Find top AI research papers in 2024 and calculate 23*56\n",
            "\n",
            "üöÄ Starting Autonomous Agent for Goal: Find top AI research papers in 2024 and calculate 23*56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-89a70addc3e3>:35: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  subtasks = llm.predict(prompt)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìã Planned Subtasks:\n",
            "1. 1. Research and identify top AI research papers published in 2024.\n",
            "2. 2. Compile a list of the selected research papers and gather relevant information about each paper.\n",
            "3. 3. Analyze the impact and significance of each research paper in the field of AI.\n",
            "4. 4. Calculate the result of 23*56 to determine the answer.\n",
            "\n",
            "üîé Working on Subtask: 1. Research and identify top AI research papers published in 2024.\n",
            "üõ† Using Tool: search\n",
            "‚úÖ Result: Originally published on Towards AI. The Top 10 AI Research Papers of 2024: Key Takeaways and How You Can Apply Them Photo by Maxim Tolchinskiy on Unsplash. As the curtains draw on 2024, it's time to reflect on the innovations that have defined the year in AI. And let's be real ‚Äî what a year it has been!\n",
            "Let's dive into the top 10 most cited AI research papers of 2024, ... Published: March 2024. Google's Gemini 1.5 stunned the industry with a 10-million-token context length and rapid ...\n",
            "\n",
            "üîé Working on Subtask: 2. Compile a list of the selected research papers and gather relevant information about each paper.\n",
            "üõ† Using Tool: search\n",
            "‚úÖ Result: Once you have a list of resources that you want to use for your research, it is time to get a hold of them so that you can actually get to the real work of reading, understanding and finally writing. This is another chance to determine if there is enough authoritative information on your topic.\n",
            "2. LOCATING PUBLISHED INFORMATION A lot of information is published on every subject imaginable. To retrieve only what's relevant to the topic, you need to identify the type and source of information you collect. The following formats are what is acceptable in scholarly research and should form the basis of your research: Journals Books ...\n",
            "\n",
            "üîé Working on Subtask: 3. Analyze the impact and significance of each research paper in the field of AI.\n",
            "üõ† Using Tool: search\n",
            "‚úÖ Result: 1. Introduction. Artificial intelligence (AI) refers to the use of computer algorithms and statistical models to process, analyze, and interpret data in research and teaching [].AI is rapidly transforming many aspects of modern society, including academic research [].As researchers increasingly debate AI technologies in academia, it is important to understand the impact of these technologies ...\n",
            "This study investigates the ethical use of Big Data and Artificial Intelligence (AI) technologies (BD + AI)‚Äîusing an empirical approach. The paper categorises the current literature and presents ...\n",
            "\n",
            "üîé Working on Subtask: 4. Calculate the result of 23*56 to determine the answer.\n",
            "üõ† Using Tool: calculate\n",
            "‚úÖ Result: Error calculating: invalid syntax (<string>, line 1)\n",
            "\n",
            "üß† Reflecting on session...\n",
            "\n",
            "üìö Final Summary of Actions:\n",
            "{'subtask': '1. Research and identify top AI research papers published in 2024.', 'tool': 'search', 'result': \"Originally published on Towards AI. The Top 10 AI Research Papers of 2024: Key Takeaways and How You Can Apply Them Photo by Maxim Tolchinskiy on Unsplash. As the curtains draw on 2024, it's time to reflect on the innovations that have defined the year in AI. And let's be real ‚Äî what a year it has been!\\nLet's dive into the top 10 most cited AI research papers of 2024, ... Published: March 2024. Google's Gemini 1.5 stunned the industry with a 10-million-token context length and rapid ...\"}\n",
            "{'subtask': '2. Compile a list of the selected research papers and gather relevant information about each paper.', 'tool': 'search', 'result': \"Once you have a list of resources that you want to use for your research, it is time to get a hold of them so that you can actually get to the real work of reading, understanding and finally writing. This is another chance to determine if there is enough authoritative information on your topic.\\n2. LOCATING PUBLISHED INFORMATION A lot of information is published on every subject imaginable. To retrieve only what's relevant to the topic, you need to identify the type and source of information you collect. The following formats are what is acceptable in scholarly research and should form the basis of your research: Journals Books ...\"}\n",
            "{'subtask': '3. Analyze the impact and significance of each research paper in the field of AI.', 'tool': 'search', 'result': '1. Introduction. Artificial intelligence (AI) refers to the use of computer algorithms and statistical models to process, analyze, and interpret data in research and teaching [].AI is rapidly transforming many aspects of modern society, including academic research [].As researchers increasingly debate AI technologies in academia, it is important to understand the impact of these technologies ...\\nThis study investigates the ethical use of Big Data and Artificial Intelligence (AI) technologies (BD + AI)‚Äîusing an empirical approach. The paper categorises the current literature and presents ...'}\n",
            "{'subtask': '4. Calculate the result of 23*56 to determine the answer.', 'tool': 'calculate', 'result': 'Error calculating: invalid syntax (<string>, line 1)'}\n",
            "{'reflection': 'I have reflected on past actions and learned better task execution sequencing.'}\n"
          ]
        }
      ]
    }
  ]
}