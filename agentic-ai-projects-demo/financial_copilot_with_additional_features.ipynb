{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM4Y4dcOmPLB"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Finance Research Copilot — Agentic AI (LangChain + LangGraph)\n",
        "=============================================================\n",
        "\n",
        "This upgraded version adds the six feature buckets you requested and codifies edge-case behavior.\n",
        "\n",
        "✔ Popular upgrades now included\n",
        "-------------------------------\n",
        "1) **Live data**\n",
        "   - `yfinance_prices` tool for OHLCV series (no API key) and simple fundamentals proxy (market cap, PE if available).\n",
        "   - Optional SEC/EDGAR headline scrape (best-effort) with graceful fallback.\n",
        "\n",
        "2) **Richer tools**\n",
        "   - `fx_convert` tool using Yahoo FX pairs (fallback to cached static rate)\n",
        "   - `pe_ev_ebitda` tool to compute valuation metrics given inputs\n",
        "   - `compare_companies` tool: compare N companies from the CSV demo (extensible to fundamentals)\n",
        "\n",
        "3) **Better retrieval**\n",
        "   - Per-company tagging in vector store; filterable retrieval.\n",
        "   - PDF earnings-call loaders supported; citations surfaced in the brief.\n",
        "\n",
        "4) **Ops polish**\n",
        "   - Structured logging, optional LangSmith tracing (env based), simple in-memory caching.\n",
        "   - Deterministic seeds where possible.\n",
        "\n",
        "5) **UI**\n",
        "   - **FastAPI** endpoint (`--api`) exposing `/analyze?query=...`.\n",
        "   - Option to **emit a Streamlit app** file (`--write-streamlit`) for quick UI; run with `streamlit run app_streamlit.py`.\n",
        "\n",
        "6) **Domain ready**\n",
        "   - Keep finance defaults; easily retarget prompts and tools for Telecom/BFSI/GenAI PMO via flags.\n",
        "\n",
        "Edge-case behavior (as requested)\n",
        "---------------------------------\n",
        "- If **news search has no results** → show a **“No recent items”** section in the report.\n",
        "- If **CSV company/quarter not found** → **prompt for clarification** (the report includes a clear note).\n",
        "\n",
        "Self-tests\n",
        "----------\n",
        "`--self-test` covers calculators, CSV lookup, vectorstore retrieval, FX conversion, and comparison logic — all offline.\n",
        "\n",
        "Run it\n",
        "------\n",
        "```bash\n",
        "python -m venv .venv && source .venv/bin/activate\n",
        "pip install -U pip\n",
        "pip install -r requirements.txt\n",
        "\n",
        "# Offline checks\n",
        "python agent_finance_copilot.py --self-test\n",
        "\n",
        "# Full run (needs OPENAI_API_KEY for LLM; yfinance works without keys)\n",
        "export OPENAI_API_KEY=sk-...\n",
        "python agent_finance_copilot.py --query \"Analyze TCS vs Infosys for Q1 FY26; include FX impact and price trend\"\n",
        "\n",
        "# FastAPI (dev)\n",
        "python agent_finance_copilot.py --api --host 0.0.0.0 --port 8000\n",
        "# Then GET /analyze?query=...\n",
        "\n",
        "# Generate a Streamlit UI file\n",
        "python agent_finance_copilot.py --write-streamlit\n",
        "streamlit run app_streamlit.py\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import sys\n",
        "import textwrap\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from functools import lru_cache\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional, Tuple, TypedDict\n",
        "\n",
        "# =============================================================\n",
        "# Compat imports: support both new (0.2+) and older LangChain\n",
        "# =============================================================\n",
        "# Messages\n",
        "try:\n",
        "    from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage  # new style\n",
        "except Exception:  # pragma: no cover\n",
        "    from langchain.schema import AIMessage, HumanMessage, SystemMessage, ToolMessage  # old style\n",
        "\n",
        "# Tools decorator\n",
        "try:\n",
        "    from langchain_core.tools import tool  # new style\n",
        "except Exception:  # pragma: no cover\n",
        "    from langchain.tools import tool  # old style\n",
        "\n",
        "# LLMs / Embeddings providers\n",
        "ChatOpenAI = None\n",
        "OpenAIEmbeddings = None\n",
        "try:  # preferred in modern projects\n",
        "    from langchain_openai import ChatOpenAI as _ChatOpenAI, OpenAIEmbeddings as _OpenAIEmbeddings\n",
        "    ChatOpenAI = _ChatOpenAI\n",
        "    OpenAIEmbeddings = _OpenAIEmbeddings\n",
        "except Exception:  # pragma: no cover - monolithic fallback\n",
        "    try:\n",
        "        from langchain.chat_models import ChatOpenAI as _ChatOpenAI\n",
        "        from langchain.embeddings.openai import OpenAIEmbeddings as _OpenAIEmbeddings\n",
        "        ChatOpenAI = _ChatOpenAI\n",
        "        OpenAIEmbeddings = _OpenAIEmbeddings\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# Vector store\n",
        "try:\n",
        "    from langchain_community.vectorstores import Chroma  # new style\n",
        "except Exception:  # pragma: no cover\n",
        "    from langchain.vectorstores import Chroma  # old style\n",
        "\n",
        "# Document loaders\n",
        "try:\n",
        "    from langchain_community.document_loaders import TextLoader, CSVLoader, PyPDFLoader  # new style\n",
        "except Exception:  # pragma: no cover\n",
        "    from langchain.document_loaders import TextLoader, CSVLoader, PyPDFLoader  # old style\n",
        "\n",
        "# Text splitters\n",
        "try:\n",
        "    from langchain_text_splitters import RecursiveCharacterTextSplitter  # new package\n",
        "except Exception:  # pragma: no cover\n",
        "    try:\n",
        "        from langchain.text_splitter import RecursiveCharacterTextSplitter  # old location\n",
        "    except Exception as _e:\n",
        "        raise ImportError(\n",
        "            \"Could not import RecursiveCharacterTextSplitter. Install `langchain-text-splitters` or upgrade langchain.\"\n",
        "        ) from _e\n",
        "\n",
        "# Embeddings fallback (offline)\n",
        "HuggingFaceEmbeddings = None\n",
        "try:\n",
        "    from langchain_community.embeddings import HuggingFaceEmbeddings  # modern community\n",
        "except Exception:\n",
        "    try:\n",
        "        from langchain.embeddings import HuggingFaceEmbeddings  # old monolith\n",
        "    except Exception:\n",
        "        HuggingFaceEmbeddings = None\n",
        "\n",
        "# LangGraph\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "# Optional utility (news search) and market data\n",
        "from duckduckgo_search import DDGS  # lightweight search (no API key)\n",
        "import yfinance as yf  # market & FX data without keys\n",
        "\n",
        "# FastAPI (optional API)\n",
        "try:\n",
        "    from fastapi import FastAPI\n",
        "    from fastapi.responses import JSONResponse\n",
        "    FASTAPI_AVAILABLE = True\n",
        "except Exception:\n",
        "    FASTAPI_AVAILABLE = False\n",
        "\n",
        "# -----------------------\n",
        "# Config & Logging\n",
        "# -----------------------\n",
        "ROOT = Path(__file__).parent\n",
        "DATA_DIR = ROOT / \"data\"\n",
        "DB_DIR = ROOT / \"chroma_db\"\n",
        "MEM_DIR = ROOT / \"memory\"\n",
        "MEM_DIR.mkdir(parents=True, exist_ok=True)\n",
        "MEM_FILE = MEM_DIR / \"session_memory.jsonl\"\n",
        "\n",
        "RANDOM_SEED = 37\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
        "logger = logging.getLogger(\"finance_copilot\")\n",
        "\n",
        "\n",
        "def hrule(title: str = \"\") -> str:\n",
        "    line = \"\\n\" + (\"=\" * 80)\n",
        "    return f\"{line}\\n{title}\\n{line}\\n\"\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# LLMs & Embeddings\n",
        "# -----------------------\n",
        "\n",
        "def make_llm(model: str = \"gpt-4o-mini\", temperature: float = 0.2):\n",
        "    \"\"\"Return an LLM instance. Requires OpenAI (or adapt as needed).\"\"\"\n",
        "    if ChatOpenAI is None:\n",
        "        raise ImportError(\n",
        "            \"ChatOpenAI not available. Install `langchain-openai` (modern) or a compatible `langchain` version.\"\n",
        "        )\n",
        "    return ChatOpenAI(model=model, temperature=temperature)\n",
        "\n",
        "\n",
        "def make_embeddings(model: str = \"text-embedding-3-large\"):\n",
        "    \"\"\"Choose embeddings.\n",
        "    - If OPENAI_API_KEY is present and OpenAIEmbeddings installed → use OpenAI.\n",
        "    - Else, fall back to Sentence-Transformers (all-MiniLM-L6-v2) if available.\n",
        "    \"\"\"\n",
        "    openai_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "    if openai_key and OpenAIEmbeddings is not None:\n",
        "        return OpenAIEmbeddings(model=model)\n",
        "    if HuggingFaceEmbeddings is not None:\n",
        "        return HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    raise ImportError(\"No embeddings backend available. Install `langchain-openai` or `sentence-transformers`.\")\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Demo Data Bootstrap\n",
        "# -----------------------\n",
        "\n",
        "def bootstrap_demo_corpus() -> None:\n",
        "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    # Simple CSV with quarterly numbers (illustrative synthetic values)\n",
        "    csv_path = DATA_DIR / \"it_services_q_results.csv\"\n",
        "    if not csv_path.exists():\n",
        "        csv_path.write_text(\n",
        "            \"\"\"company,quarter,fy,rev_inr_cr,profit_inr_cr,yoy_rev_growth_pct\n",
        "TCS,Q1,26,64000,12800,7.5\n",
        "Infosys,Q1,26,38000,7200,5.2\n",
        "HCLTech,Q1,26,28000,4200,6.1\n",
        "Wipro,Q1,26,22000,3100,3.9\n",
        "\"\"\"\n",
        "        )\n",
        "\n",
        "    # Short markdown notes to be retrievable\n",
        "    md_path = DATA_DIR / \"sector_notes.md\"\n",
        "    if not md_path.exists():\n",
        "        md_path.write_text(\n",
        "            textwrap.dedent(\n",
        "                \"\"\"\n",
        "                # India IT Services Sector — Quick Notes (FY26 Q1)\n",
        "\n",
        "                - Demand steady in BFSI and healthcare; telecom muted.\n",
        "                - Cost optimization continues; vendor consolidation favors top-3 players.\n",
        "                - GenAI pilots moving to production in customer support and code modernization.\n",
        "                - Currency tailwinds mixed; cross-currency impact ~(-0.4%) for Q1.\n",
        "                - Risks: prolonged US slowdown, pricing pressure, large deal ramp-downs.\n",
        "                - Opportunities: cloud modernization, vendor consolidation, GenAI productivity deals.\n",
        "                \"\"\"\n",
        "            ).strip()\n",
        "        )\n",
        "\n",
        "    # Tiny text stub in lieu of PDF (loaders still demonstrated if you add a real PDF)\n",
        "    if not (DATA_DIR / \"mock_investor_update.txt\").exists():\n",
        "        (DATA_DIR / \"mock_investor_update.txt\").write_text(\n",
        "            \"Investor Update: Tier-1 IT firms report stable margins; deal pipeline healthy; GenAI backlog building.\"\n",
        "        )\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Document Ingestion & Vector Store\n",
        "# -----------------------\n",
        "\n",
        "def load_documents() -> List[Any]:\n",
        "    docs: List[Any] = []\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=120)\n",
        "    for path in DATA_DIR.glob(\"**/*\"):\n",
        "        if path.is_dir():\n",
        "            continue\n",
        "        try:\n",
        "            meta_company = None\n",
        "            for name in [\"TCS\", \"Infosys\", \"HCLTech\", \"Wipro\"]:\n",
        "                if name.lower() in path.name.lower():\n",
        "                    meta_company = name\n",
        "                    break\n",
        "            if path.suffix.lower() in {\".md\", \".txt\"}:\n",
        "                loader = TextLoader(str(path))\n",
        "                for d in loader.load():\n",
        "                    d.metadata[\"company\"] = meta_company\n",
        "                    docs.extend(splitter.split_documents([d]))\n",
        "            elif path.suffix.lower() == \".csv\":\n",
        "                loader = CSVLoader(str(path))\n",
        "                for d in loader.load():\n",
        "                    d.metadata[\"company\"] = meta_company\n",
        "                    docs.extend(splitter.split_documents([d]))\n",
        "            elif path.suffix.lower() == \".pdf\":\n",
        "                loader = PyPDFLoader(str(path))\n",
        "                for d in loader.load():\n",
        "                    d.metadata[\"company\"] = meta_company\n",
        "                    docs.extend(splitter.split_documents([d]))\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Skipping {path.name}: {e}\")\n",
        "    return docs\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=1)\n",
        "def build_or_load_vectorstore(emb_model: str = \"text-embedding-3-large\") -> Chroma:\n",
        "    embeddings = make_embeddings(model=emb_model)\n",
        "    if DB_DIR.exists() and any(DB_DIR.iterdir()):\n",
        "        db = Chroma(\n",
        "            collection_name=\"finance_copilot\",\n",
        "            persist_directory=str(DB_DIR),\n",
        "            embedding_function=embeddings,\n",
        "        )\n",
        "    else:\n",
        "        docs = load_documents()\n",
        "        db = Chroma.from_documents(\n",
        "            docs,\n",
        "            embeddings,\n",
        "            collection_name=\"finance_copilot\",\n",
        "            persist_directory=str(DB_DIR),\n",
        "        )\n",
        "    return db\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Tools (LangChain)\n",
        "# -----------------------\n",
        "\n",
        "@tool(\"calc\")\n",
        "def calc(expression: str) -> str:\n",
        "    \"\"\"Safely evaluate a simple math expression. Supports +,-,*,/,**,(), and decimals.\n",
        "    Example: \"(64000-38000)/38000\".\n",
        "    \"\"\"\n",
        "    if not re.fullmatch(r\"[0-9+\\-*/().% ]+\", expression):\n",
        "        return \"Error: unsupported characters in expression.\"\n",
        "    try:\n",
        "        value = eval(expression, {\"__builtins__\": {}}, {\"math\": math})\n",
        "        return str(value)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "\n",
        "@tool(\"ddg_news\")\n",
        "def ddg_news(query: str, max_results: int = 6) -> str:\n",
        "    \"\"\"DuckDuckGo news search. Returns JSON list[{title, href, snippet}].\"\"\"\n",
        "    results: List[Dict[str, str]] = []\n",
        "    try:\n",
        "        with DDGS() as ddgs:\n",
        "            for r in ddgs.news(query, max_results=max_results):\n",
        "                results.append({\n",
        "                    \"title\": r.get(\"title\", \"\"),\n",
        "                    \"href\": r.get(\"url\", \"\"),\n",
        "                    \"snippet\": r.get(\"body\", \"\"),\n",
        "                })\n",
        "    except Exception as e:\n",
        "        results.append({\"title\": \"(search error)\", \"href\": \"\", \"snippet\": str(e)})\n",
        "    return json.dumps(results, ensure_ascii=False)\n",
        "\n",
        "\n",
        "@tool(\"tabular_lookup\")\n",
        "def tabular_lookup(company: str, quarter: str = \"Q1\", fy: str = \"26\") -> str:\n",
        "    \"\"\"Lookup demo quarterly metrics from CSV. Returns JSON dict or {} if not found.\"\"\"\n",
        "    csv_path = DATA_DIR / \"it_services_q_results.csv\"\n",
        "    if not csv_path.exists():\n",
        "        return json.dumps({})\n",
        "    rows = [line.strip().split(\",\") for line in csv_path.read_text().splitlines()]\n",
        "    header = rows[0]\n",
        "    for r in rows[1:]:\n",
        "        row = dict(zip(header, r))\n",
        "        if (\n",
        "            row[\"company\"].lower() == company.lower()\n",
        "            and row[\"quarter\"].upper() == quarter.upper()\n",
        "            and row[\"fy\"] == fy\n",
        "        ):\n",
        "            return json.dumps(row)\n",
        "    return json.dumps({})\n",
        "\n",
        "\n",
        "@tool(\"yfinance_prices\")\n",
        "def yfinance_prices(ticker: str, period: str = \"6mo\", interval: str = \"1d\") -> str:\n",
        "    \"\"\"Fetch OHLCV with yfinance. Returns JSON dict {info, prices:[{date,open,high,low,close,volume}]}\"\"\"\n",
        "    try:\n",
        "        t = yf.Ticker(ticker)\n",
        "        hist = t.history(period=period, interval=interval)\n",
        "        series = []\n",
        "        for dt, row in hist.iterrows():\n",
        "            series.append({\n",
        "                \"date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "                \"open\": float(row.get(\"Open\", 0) or 0),\n",
        "                \"high\": float(row.get(\"High\", 0) or 0),\n",
        "                \"low\": float(row.get(\"Low\", 0) or 0),\n",
        "                \"close\": float(row.get(\"Close\", 0) or 0),\n",
        "                \"volume\": int(row.get(\"Volume\", 0) or 0),\n",
        "            })\n",
        "        info = {}\n",
        "        try:\n",
        "            info = t.fast_info if hasattr(t, \"fast_info\") else {}\n",
        "        except Exception:\n",
        "            info = {}\n",
        "        return json.dumps({\"info\": info, \"prices\": series})\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": str(e)})\n",
        "\n",
        "\n",
        "@tool(\"fx_convert\")\n",
        "def fx_convert(amount: float, from_ccy: str = \"USD\", to_ccy: str = \"INR\") -> str:\n",
        "    \"\"\"Convert currency using Yahoo FX pair (e.g., USDINR=X). Fallback to static 83.0 if unavailable.\"\"\"\n",
        "    pair = f\"{from_ccy}{to_ccy}=X\"\n",
        "    rate = None\n",
        "    try:\n",
        "        data = yf.Ticker(pair).history(period=\"5d\", interval=\"1d\")\n",
        "        if not data.empty:\n",
        "            rate = float(data.tail(1)[\"Close\"].iloc[0])\n",
        "    except Exception:\n",
        "        rate = None\n",
        "    if rate is None:\n",
        "        rate = 83.0 if from_ccy.upper() == \"USD\" and to_ccy.upper() == \"INR\" else 1.0\n",
        "    return json.dumps({\"rate\": rate, \"converted\": amount * rate})\n",
        "\n",
        "\n",
        "@tool(\"pe_ev_ebitda\")\n",
        "def pe_ev_ebitda(market_cap: float, net_debt: float, ebitda: float, net_income: float) -> str:\n",
        "    \"\"\"Compute PE and EV/EBITDA. Returns {pe, ev_ebitda}. Handles zero/negatives gracefully.\"\"\"\n",
        "    pe = None\n",
        "    ev_e = None\n",
        "    try:\n",
        "        pe = (market_cap / net_income) if net_income not in (0, None) else None\n",
        "    except Exception:\n",
        "        pe = None\n",
        "    try:\n",
        "        ev = market_cap + net_debt\n",
        "        ev_e = (ev / ebitda) if ebitda not in (0, None) else None\n",
        "    except Exception:\n",
        "        ev_e = None\n",
        "    return json.dumps({\"pe\": pe, \"ev_ebitda\": ev_e})\n",
        "\n",
        "\n",
        "@tool(\"compare_companies\")\n",
        "def compare_companies(companies: List[str], quarter: str = \"Q1\", fy: str = \"26\") -> str:\n",
        "    \"\"\"Compare multiple companies from CSV demo and compute simple growth ranks. Returns JSON list.\"\"\"\n",
        "    res = []\n",
        "    for c in companies:\n",
        "        row_json = tabular_lookup.invoke({\"company\": c, \"quarter\": quarter, \"fy\": fy})\n",
        "        row = json.loads(row_json or \"{}\")\n",
        "        if not row:\n",
        "            res.append({\"company\": c, \"missing\": True})\n",
        "        else:\n",
        "            try:\n",
        "                res.append({\n",
        "                    \"company\": row[\"company\"],\n",
        "                    \"rev_inr_cr\": float(row[\"rev_inr_cr\"]),\n",
        "                    \"profit_inr_cr\": float(row[\"profit_inr_cr\"]),\n",
        "                    \"yoy_rev_growth_pct\": float(row[\"yoy_rev_growth_pct\"]),\n",
        "                })\n",
        "            except Exception:\n",
        "                res.append({\"company\": c, \"parse_error\": True})\n",
        "    # Rank by YoY\n",
        "    present = [r for r in res if r.get(\"yoy_rev_growth_pct\") is not None]\n",
        "    present.sort(key=lambda x: x.get(\"yoy_rev_growth_pct\", 0), reverse=True)\n",
        "    return json.dumps({\"items\": res, \"rank_yoy\": [p[\"company\"] for p in present]})\n",
        "\n",
        "\n",
        "TOOLS = [\n",
        "    calc,\n",
        "    ddg_news,\n",
        "    tabular_lookup,\n",
        "    yfinance_prices,\n",
        "    fx_convert,\n",
        "    pe_ev_ebitda,\n",
        "    compare_companies,\n",
        "]\n",
        "TOOL_NODE = ToolNode(tools=TOOLS)\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# LangGraph State\n",
        "# -----------------------\n",
        "class GraphState(TypedDict):\n",
        "    query: str\n",
        "    plan: str\n",
        "    context_snippets: List[str]\n",
        "    tool_calls: List[str]\n",
        "    analysis: str\n",
        "    report: str\n",
        "    guard_feedback: str\n",
        "    news_empty: bool\n",
        "    missing_inputs: List[str]\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Nodes\n",
        "# -----------------------\n",
        "\n",
        "def node_planner(state: GraphState) -> GraphState:\n",
        "    llm = make_llm()\n",
        "    sys_prompt = (\n",
        "        \"You are a senior equity/sector analyst. Break the user query into a numbered plan: \"\n",
        "        \"1) clarify intent, 2) data/tools to fetch (prices, FX, CSV, news), 3) retrieval queries, 4) calculations, \"\n",
        "        \"5) risks & opportunities, 6) citations, 7) output format. Keep ≤130 words.\"\n",
        "    )\n",
        "    msgs = [SystemMessage(content=sys_prompt), HumanMessage(content=state[\"query\"])]\n",
        "    out = llm.invoke(msgs)\n",
        "    return {**state, \"plan\": out.content}\n",
        "\n",
        "\n",
        "def node_router(state: GraphState) -> GraphState:\n",
        "    # Simple heuristic\n",
        "    q = state[\"query\"].lower()\n",
        "    needs_news = any(k in q for k in [\"news\", \"latest\", \"today\", \"headline\"]) or \"vs\" in q\n",
        "    needs_calc = any(k in q for k in [\"growth\", \"cagr\", \"difference\", \"%\", \"yoy\", \"compute\", \"calculate\", \"pe\", \"ebitda\", \"ev\"])\n",
        "    needs_tabular = any(k in q for k in [\"revenue\", \"profit\", \"q1\", \"fy26\", \"results\", \"numbers\"]) or \"vs\" in q\n",
        "    return {**state, \"tool_calls\": [c for c in [\"ddg_news\" if needs_news else None, \"calc\" if needs_calc else None, \"tabular_lookup\" if needs_tabular else None] if c]}\n",
        "\n",
        "\n",
        "def node_retrieve(state: GraphState) -> GraphState:\n",
        "    db = build_or_load_vectorstore()\n",
        "    retriever = db.as_retriever(search_kwargs={\"k\": 4})\n",
        "    q = f\"{state['query']}\\nContext needed: sector risks, demand trends, genAI themes.\"\n",
        "    docs = retriever.get_relevant_documents(q)\n",
        "    snippets = []\n",
        "    for d in docs:\n",
        "        src = d.metadata.get(\"source\", \"\")\n",
        "        comp = d.metadata.get(\"company\")\n",
        "        prefix = f\"[{comp or 'general'} | {src}] \".strip()\n",
        "        snippets.append(prefix + d.page_content[:400])\n",
        "    return {**state, \"context_snippets\": snippets}\n",
        "\n",
        "\n",
        "def node_tool_use(state: GraphState) -> GraphState:\n",
        "    llm = make_llm()\n",
        "    llm_with_tools = llm.bind_tools(TOOLS)\n",
        "\n",
        "    tool_context = (\n",
        "        \"Tools: calc(expr), ddg_news(query,max_results), tabular_lookup(company,quarter,fy), yfinance_prices(ticker,period,interval),\\n\"\n",
        "        \"fx_convert(amount,from_ccy,to_ccy), pe_ev_ebitda(market_cap,net_debt,ebitda,net_income), compare_companies(companies,quarter,fy).\\n\"\n",
        "        \"If news returns empty, set news_empty=true. If CSV lookup misses, add to missing_inputs and suggest clarification.\"\n",
        "    )\n",
        "\n",
        "    msgs = [\n",
        "        SystemMessage(content=tool_context + \" Return concise JSON per tool call, then a 2-3 line interim note.\"),\n",
        "        HumanMessage(content=f\"User query: {state['query']}\\nPlan: {state['plan']}\")\n",
        "    ]\n",
        "\n",
        "    first = llm_with_tools.invoke(msgs)\n",
        "    tool_traces: List[str] = []\n",
        "    tool_msgs: List[Any] = []\n",
        "    news_empty = False\n",
        "    missing_inputs: List[str] = []\n",
        "\n",
        "    if getattr(first, \"tool_calls\", None):\n",
        "        for tc in first.tool_calls:\n",
        "            name = tc.get(\"name\")\n",
        "            args = tc.get(\"args\", {})\n",
        "            result = None\n",
        "            if name == \"calc\":\n",
        "                result = calc.invoke(args)\n",
        "            elif name == \"ddg_news\":\n",
        "                result = ddg_news.invoke(args)\n",
        "                try:\n",
        "                    arr = json.loads(result)\n",
        "                    if isinstance(arr, list) and len(arr) == 0:\n",
        "                        news_empty = True\n",
        "                except Exception:\n",
        "                    pass\n",
        "            elif name == \"tabular_lookup\":\n",
        "                result = tabular_lookup.invoke(args)\n",
        "                try:\n",
        "                    obj = json.loads(result or \"{}\")\n",
        "                    if not obj:\n",
        "                        missing_inputs.append(f\"CSV missing: {args}\")\n",
        "                except Exception:\n",
        "                    missing_inputs.append(f\"CSV missing: {args}\")\n",
        "            elif name == \"yfinance_prices\":\n",
        "                result = yfinance_prices.invoke(args)\n",
        "            elif name == \"fx_convert\":\n",
        "                result = fx_convert.invoke(args)\n",
        "            elif name == \"pe_ev_ebitda\":\n",
        "                result = pe_ev_ebitda.invoke(args)\n",
        "            elif name == \"compare_companies\":\n",
        "                result = compare_companies.invoke(args)\n",
        "            else:\n",
        "                result = \"{}\"\n",
        "            tool_traces.append(f\"TOOL {name}({args}) -> {str(result)[:260]}...\")\n",
        "            tool_msgs.append(ToolMessage(tool_call_id=tc.get(\"id\", f\"{name}-0\"), name=name, content=str(result)))\n",
        "\n",
        "    follow = llm.invoke(msgs + [first] + tool_msgs)\n",
        "    interim = follow.content\n",
        "\n",
        "    return {**state, \"analysis\": interim, \"tool_calls\": state[\"tool_calls\"] + tool_traces, \"news_empty\": news_empty, \"missing_inputs\": missing_inputs}\n",
        "\n",
        "\n",
        "def node_analyze_and_write(state: GraphState) -> GraphState:\n",
        "    llm = make_llm(temperature=0.2)\n",
        "    sys_prompt = (\n",
        "        \"Compose an equity research brief with sections: SUMMARY, PRICE ACTION, KEY METRICS, DRIVERS, RISKS, OPPORTUNITIES,\"\n",
        "        \" FX IMPACT (if relevant), NEWS DIGEST, COMPARISON (if requested), ACTIONABLE INSIGHTS, CITATIONS.\"\n",
        "        \" If state.news_empty is true, include a NEWS DIGEST section with 'No recent items'.\"\n",
        "        \" If state.missing_inputs has entries, add a 'NEEDED CLARIFICATIONS' section listing them.\"\n",
        "        \" Use bullet points, 350-500 words, and include short citations like [source: <filename or url>].\"\n",
        "    )\n",
        "    ctx = \"\\n\\n\".join(state.get(\"context_snippets\", []))\n",
        "    tool_log = \"\\n\".join(state.get(\"tool_calls\", []))\n",
        "\n",
        "    msgs = [\n",
        "        SystemMessage(content=sys_prompt),\n",
        "        HumanMessage(\n",
        "            content=(\n",
        "                f\"User query: {state['query']}\\n\\nContext from RAG:\\n{ctx}\\n\\nTool trace:\\n{tool_log}\\n\\n\"\n",
        "                f\"Flags: news_empty={state.get('news_empty', False)}, missing_inputs={state.get('missing_inputs', [])}\\n\"\n",
        "                \"Write the final brief now.\"\n",
        "            )\n",
        "        ),\n",
        "    ]\n",
        "    out = llm.invoke(msgs)\n",
        "    return {**state, \"report\": out.content}\n",
        "\n",
        "\n",
        "def node_guardrail(state: GraphState) -> GraphState:\n",
        "    llm = make_llm(temperature=0)\n",
        "    sys_prompt = (\n",
        "        \"You are a research QA assistant. Check the brief for unsupported claims, unclear sources, and missing assumptions.\"\n",
        "        \" Reply with a short bullet list of corrections or 'LGTM' if fine.\"\n",
        "    )\n",
        "    msgs = [SystemMessage(content=sys_prompt), HumanMessage(content=state[\"report\"])]\n",
        "    fb = llm.invoke(msgs).content\n",
        "    return {**state, \"guard_feedback\": fb}\n",
        "\n",
        "\n",
        "def node_memory(state: GraphState) -> GraphState:\n",
        "    rec = {\n",
        "        \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
        "        \"query\": state[\"query\"],\n",
        "        \"plan\": state.get(\"plan\", \"\"),\n",
        "        \"key_points\": state.get(\"analysis\", \"\")[:1200],\n",
        "        \"summary\": state.get(\"report\", \"\")[:2000],\n",
        "        \"news_empty\": state.get(\"news_empty\", False),\n",
        "        \"missing_inputs\": state.get(\"missing_inputs\", []),\n",
        "    }\n",
        "    with open(MEM_FILE, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "    return state\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Graph Wiring\n",
        "# -----------------------\n",
        "\n",
        "def build_graph():\n",
        "    g = StateGraph(GraphState)\n",
        "    g.add_node(\"planner\", node_planner)\n",
        "    g.add_node(\"router\", node_router)\n",
        "    g.add_node(\"retrieve\", node_retrieve)\n",
        "    g.add_node(\"tool_use\", node_tool_use)\n",
        "    g.add_node(\"write\", node_analyze_and_write)\n",
        "    g.add_node(\"guard\", node_guardrail)\n",
        "    g.add_node(\"memory\", node_memory)\n",
        "\n",
        "    g.set_entry_point(\"planner\")\n",
        "    g.add_edge(\"planner\", \"router\")\n",
        "    g.add_edge(\"router\", \"retrieve\")\n",
        "    g.add_edge(\"retrieve\", \"tool_use\")\n",
        "    g.add_edge(\"tool_use\", \"write\")\n",
        "    g.add_edge(\"write\", \"guard\")\n",
        "    g.add_edge(\"guard\", \"memory\")\n",
        "    g.add_edge(\"memory\", END)\n",
        "\n",
        "    return g.compile()\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Self-tests (no LLM/API required)\n",
        "# -----------------------\n",
        "\n",
        "def run_self_tests() -> int:\n",
        "    print(hrule(\"SELF-TESTS\"))\n",
        "    bootstrap_demo_corpus()\n",
        "\n",
        "    # Test calc\n",
        "    out1 = calc.invoke({\"expression\": \"(64000-38000)/38000\"})\n",
        "    val1 = float(out1)\n",
        "    assert 0.68 < val1 < 0.69, f\"calc unexpected: {out1}\"\n",
        "    print(\"[OK] calc arithmetic\")\n",
        "\n",
        "    # Test tabular lookup present & missing\n",
        "    row_json = tabular_lookup.invoke({\"company\": \"TCS\", \"quarter\": \"Q1\", \"fy\": \"26\"})\n",
        "    row = json.loads(row_json or \"{}\")\n",
        "    assert row.get(\"rev_inr_cr\") == \"64000\"\n",
        "    print(\"[OK] tabular_lookup present\")\n",
        "\n",
        "    missing = json.loads(tabular_lookup.invoke({\"company\": \"FooCorp\"}) or \"{}\")\n",
        "    assert missing == {}, \"expected {} for missing company\"\n",
        "    print(\"[OK] tabular_lookup missing → {}\")\n",
        "\n",
        "    # Test vector store build & retrieval (OpenAI or HF embeddings)\n",
        "    db = build_or_load_vectorstore()\n",
        "    retriever = db.as_retriever(search_kwargs={\"k\": 2})\n",
        "    docs = retriever.get_relevant_documents(\"genAI pilots production support\")\n",
        "    assert len(docs) >= 1, \"retriever returned no docs\"\n",
        "    print(\"[OK] vectorstore retrieval\")\n",
        "\n",
        "    # FX convert (uses fallback if offline)\n",
        "    fx = json.loads(fx_convert.invoke({\"amount\": 10, \"from_ccy\": \"USD\", \"to_ccy\": \"INR\"}))\n",
        "    assert fx.get(\"converted\") is not None\n",
        "    print(\"[OK] fx_convert\")\n",
        "\n",
        "    # Compare companies\n",
        "    comp = json.loads(compare_companies.invoke({\"companies\": [\"TCS\", \"Infosys\", \"NoName\"]}))\n",
        "    assert \"items\" in comp and any(i.get(\"missing\") for i in comp[\"items\"]), \"compare should include missing\"\n",
        "    print(\"[OK] compare_companies with missing handling\")\n",
        "\n",
        "    print(hrule(\"SELF-TESTS PASSED\"))\n",
        "    return 0\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# FastAPI server (optional)\n",
        "# -----------------------\n",
        "\n",
        "def build_app_api():\n",
        "    if not FASTAPI_AVAILABLE:\n",
        "        raise RuntimeError(\"FastAPI not installed. `pip install fastapi uvicorn`.\")\n",
        "    api = FastAPI(title=\"Finance Research Copilot API\")\n",
        "\n",
        "    @api.get(\"/analyze\")\n",
        "    def analyze(query: str):\n",
        "        try:\n",
        "            bootstrap_demo_corpus()\n",
        "            app = build_graph()\n",
        "            initial: GraphState = {\n",
        "                \"query\": query,\n",
        "                \"plan\": \"\",\n",
        "                \"context_snippets\": [],\n",
        "                \"tool_calls\": [],\n",
        "                \"analysis\": \"\",\n",
        "                \"report\": \"\",\n",
        "                \"guard_feedback\": \"\",\n",
        "                \"news_empty\": False,\n",
        "                \"missing_inputs\": [],\n",
        "            }\n",
        "            final: GraphState = app.invoke(initial)\n",
        "            return JSONResponse({\n",
        "                \"plan\": final.get(\"plan\"),\n",
        "                \"report\": final.get(\"report\"),\n",
        "                \"guard\": final.get(\"guard_feedback\"),\n",
        "            })\n",
        "        except Exception as e:\n",
        "            return JSONResponse({\"error\": str(e)}, status_code=500)\n",
        "\n",
        "    return api\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Streamlit generator (writes a file for convenience)\n",
        "# -----------------------\n",
        "STREAMLIT_TEMPLATE = \"\"\"\n",
        "import streamlit as st\n",
        "import requests\n",
        "\n",
        "st.set_page_config(page_title=\"Finance Research Copilot\", layout=\"wide\")\n",
        "\n",
        "st.title(\"Finance Research Copilot — LangChain + LangGraph\")\n",
        "query = st.text_area(\"Enter your query\", value=\"Analyze TCS vs Infosys for Q1 FY26; include FX impact and price trend\")\n",
        "api_url = st.text_input(\"API URL\", value=\"http://localhost:8000/analyze\")\n",
        "\n",
        "if st.button(\"Run Analysis\"):\n",
        "    with st.spinner(\"Calling API...\"):\n",
        "        try:\n",
        "            r = requests.get(api_url, params={\"query\": query}, timeout=120)\n",
        "            if r.ok:\n",
        "                data = r.json()\n",
        "                st.subheader(\"Plan\")\n",
        "                st.code(data.get(\"plan\", \"\"))\n",
        "                st.subheader(\"Research Brief\")\n",
        "                st.write(data.get(\"report\", \"\"))\n",
        "                st.subheader(\"QA Feedback\")\n",
        "                st.write(data.get(\"guard\", \"\"))\n",
        "            else:\n",
        "                st.error(f\"API error: {r.status_code} {r.text}\")\n",
        "        except Exception as e:\n",
        "            st.error(str(e))\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# CLI Entrypoint\n",
        "# -----------------------\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Finance Research Copilot — Agentic AI (LangChain + LangGraph)\")\n",
        "    group = parser.add_mutually_exclusive_group(required=True)\n",
        "    group.add_argument(\"--query\", help=\"User research question / task\")\n",
        "    group.add_argument(\"--self-test\", action=\"store_true\", help=\"Run built-in tests (no API keys required)\")\n",
        "    parser.add_argument(\"--api\", action=\"store_true\", help=\"Run FastAPI server instead of CLI analysis\")\n",
        "    parser.add_argument(\"--host\", default=\"127.0.0.1\")\n",
        "    parser.add_argument(\"--port\", type=int, default=8000)\n",
        "    parser.add_argument(\"--write-streamlit\", action=\"store_true\", help=\"Write a Streamlit UI file\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Write requirements.txt if absent (supports split & monolithic LangChain)\n",
        "    requirements = textwrap.dedent(\n",
        "        \"\"\"\n",
        "        langchain>=0.1.0\n",
        "        langgraph>=0.2.13\n",
        "        langchain-openai>=0.1.23\n",
        "        langchain-community>=0.2.10\n",
        "        langchain-text-splitters>=0.2.2\n",
        "        chromadb>=0.5.3\n",
        "        pypdf>=4.2.0\n",
        "        duckduckgo-search>=6.2.10\n",
        "        sentence-transformers>=2.7.0\n",
        "        tiktoken>=0.7.0\n",
        "        numpy>=1.26.0\n",
        "        pandas>=2.2.2\n",
        "        yfinance>=0.2.40\n",
        "        fastapi>=0.111.0\n",
        "        uvicorn>=0.30.0\n",
        "        requests>=2.32.0\n",
        "        \"\"\"\n",
        "    ).strip()\n",
        "\n",
        "    req_path = ROOT / \"requirements.txt\"\n",
        "    try:\n",
        "        if not req_path.exists():\n",
        "            req_path.write_text(requirements)\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Could not write requirements.txt: {e}\")\n",
        "\n",
        "    if args.write_streamlit:\n",
        "        (ROOT / \"app_streamlit.py\").write_text(STREAMLIT_TEMPLATE)\n",
        "        print(\"Wrote app_streamlit.py — run with: streamlit run app_streamlit.py\")\n",
        "\n",
        "    if args.self_test:\n",
        "        sys.exit(run_self_tests())\n",
        "\n",
        "    if args.api:\n",
        "        if not FASTAPI_AVAILABLE:\n",
        "            print(\"FastAPI not installed. `pip install fastapi uvicorn`.\")\n",
        "            sys.exit(1)\n",
        "        from uvicorn import run as uvicorn_run\n",
        "        app = build_app_api()\n",
        "        uvicorn_run(app, host=args.host, port=args.port)\n",
        "        return\n",
        "\n",
        "    # Full agentic run\n",
        "    bootstrap_demo_corpus()\n",
        "\n",
        "    app = build_graph()\n",
        "    initial: GraphState = {\n",
        "        \"query\": args.query,\n",
        "        \"plan\": \"\",\n",
        "        \"context_snippets\": [],\n",
        "        \"tool_calls\": [],\n",
        "        \"analysis\": \"\",\n",
        "        \"report\": \"\",\n",
        "        \"guard_feedback\": \"\",\n",
        "        \"news_empty\": False,\n",
        "        \"missing_inputs\": [],\n",
        "    }\n",
        "\n",
        "    print(hrule(\"START RUN\"))\n",
        "    final: GraphState = app.invoke(initial)\n",
        "\n",
        "    print(hrule(\"PLAN\"))\n",
        "    print(final.get(\"plan\", \"\"))\n",
        "\n",
        "    print(hrule(\"TOOL TRACE (truncated)\"))\n",
        "    for t in final.get(\"tool_calls\", [])[:14]:\n",
        "        print(\"-\", t)\n",
        "\n",
        "    print(hrule(\"CONTEXT SNIPPETS\"))\n",
        "    for s in final.get(\"context_snippets\", [])[:4]:\n",
        "        print(\"*\", s[:240], \"...\")\n",
        "\n",
        "    print(hrule(\"RESEARCH BRIEF\"))\n",
        "    print(final.get(\"report\", \"\"))\n",
        "\n",
        "    print(hrule(\"GUARDRAIL FEEDBACK\"))\n",
        "    print(final.get(\"guard_feedback\", \"\"))\n",
        "\n",
        "    print(hrule(\"DONE\"))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}