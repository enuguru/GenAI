{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea0MrcHPCXWq",
        "outputId": "6bae1265-2190-4ffe-9f6e-3b87cc82c0de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2026.1.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "\n",
        "# Initialize the Hugging Face API\n",
        "api = HfApi()\n",
        "\n",
        "# Fetch the list of models\n",
        "models = api.list_models()\n",
        "\n",
        "# Print details of the models\n",
        "count = 0\n",
        "for model in models:\n",
        "    print(f\"Model ID: {model.modelId}\")\n",
        "    print(f\"Model Name: {model.modelId}\")\n",
        "    print(f\"Pipeline Tag: {model.pipeline_tag}\")\n",
        "    print(f\"Tags: {model.tags}\")\n",
        "    print(\"-\" * 80)\n",
        "    if count == 20:\n",
        "      break;\n",
        "    count = count + 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwRWUrXuCfmp",
        "outputId": "06119a49-06b8-4f24-a108-f5856f97a101"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ID: Lightricks/LTX-2\n",
            "Model Name: Lightricks/LTX-2\n",
            "Pipeline Tag: image-to-video\n",
            "Tags: ['diffusers', 'safetensors', 'image-to-video', 'text-to-video', 'video-to-video', 'image-text-to-video', 'audio-to-video', 'text-to-audio', 'video-to-audio', 'audio-to-audio', 'text-to-audio-video', 'image-to-audio-video', 'image-text-to-audio-video', 'ltx-2', 'ltx-video', 'ltxv', 'lightricks', 'en', 'de', 'es', 'fr', 'ja', 'ko', 'zh', 'it', 'pt', 'arxiv:2601.03233', 'license:other', 'diffusers:LTX2Pipeline', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: fal/Qwen-Image-Edit-2511-Multiple-Angles-LoRA\n",
            "Model Name: fal/Qwen-Image-Edit-2511-Multiple-Angles-LoRA\n",
            "Pipeline Tag: image-to-image\n",
            "Tags: ['diffusers', 'qwen', 'qwen-image-edit', 'qwen-image-edit-2511', 'lora', 'multi-angle', 'camera-angles', 'camera-control', 'image-editing', 'image-to-image', 'gaussian-splatting', 'fal', 'en', 'base_model:Qwen/Qwen-Image-Edit-2511', 'base_model:adapter:Qwen/Qwen-Image-Edit-2511', 'license:apache-2.0', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: tencent/HY-MT1.5-1.8B\n",
            "Model Name: tencent/HY-MT1.5-1.8B\n",
            "Pipeline Tag: translation\n",
            "Tags: ['transformers', 'safetensors', 'hunyuan_v1_dense', 'text-generation', 'translation', 'zh', 'en', 'fr', 'pt', 'es', 'ja', 'tr', 'ru', 'ar', 'ko', 'th', 'it', 'de', 'vi', 'ms', 'id', 'tl', 'hi', 'pl', 'cs', 'nl', 'km', 'my', 'fa', 'gu', 'ur', 'te', 'mr', 'he', 'bn', 'ta', 'uk', 'bo', 'kk', 'mn', 'ug', 'arxiv:2512.24092', 'endpoints_compatible', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: nvidia/nemotron-speech-streaming-en-0.6b\n",
            "Model Name: nvidia/nemotron-speech-streaming-en-0.6b\n",
            "Pipeline Tag: automatic-speech-recognition\n",
            "Tags: ['nemo', 'speech-recognition', 'cache-aware ASR', 'automatic-speech-recognition', 'streaming-asr', 'speech', 'audio', 'FastConformer', 'RNNT', 'Parakeet', 'ASR', 'pytorch', 'NeMo', 'dataset:nvidia/Granary', 'dataset:YTC', 'dataset:Yodas2', 'dataset:LibriLight', 'dataset:librispeech_asr', 'dataset:fisher_corpus', 'dataset:Switchboard-1', 'dataset:WSJ-0', 'dataset:WSJ-1', 'dataset:National-Singapore-Corpus-Part-1', 'dataset:National-Singapore-Corpus-Part-6', 'dataset:vctk', 'dataset:voxpopuli', 'dataset:europarl', 'dataset:multilingual_librispeech', 'dataset:fleurs', 'dataset:mozilla-foundation/common_voice_8_0', 'dataset:MLCommons/peoples_speech', 'dataset:google/speech_commands', 'arxiv:2312.17279', 'arxiv:2305.05084', 'license:other', 'model-index', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: LiquidAI/LFM2.5-1.2B-Instruct\n",
            "Model Name: LiquidAI/LFM2.5-1.2B-Instruct\n",
            "Pipeline Tag: text-generation\n",
            "Tags: ['transformers', 'safetensors', 'lfm2', 'text-generation', 'liquid', 'lfm2.5', 'edge', 'conversational', 'en', 'ar', 'zh', 'fr', 'de', 'ja', 'ko', 'es', 'arxiv:2511.23404', 'base_model:LiquidAI/LFM2.5-1.2B-Base', 'base_model:finetune:LiquidAI/LFM2.5-1.2B-Base', 'license:other', 'endpoints_compatible', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: LiquidAI/LFM2.5-Audio-1.5B\n",
            "Model Name: LiquidAI/LFM2.5-Audio-1.5B\n",
            "Pipeline Tag: audio-to-audio\n",
            "Tags: ['liquid-audio', 'safetensors', 'liquid', 'lfm2', 'audio', 'lfm2-audio', 'speech-to-speech', 'audio-to-audio', 'en', 'arxiv:2511.23404', 'base_model:LiquidAI/LFM2-1.2B', 'base_model:finetune:LiquidAI/LFM2-1.2B', 'license:other', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: Kijai/LTXV2_comfy\n",
            "Model Name: Kijai/LTXV2_comfy\n",
            "Pipeline Tag: None\n",
            "Tags: ['gguf', 'comfyui', 'license:other', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: naver-hyperclovax/HyperCLOVAX-SEED-Think-32B\n",
            "Model Name: naver-hyperclovax/HyperCLOVAX-SEED-Think-32B\n",
            "Pipeline Tag: text-generation\n",
            "Tags: ['transformers', 'safetensors', 'vlm', 'text-generation', 'conversational', 'custom_code', 'license:other', 'endpoints_compatible', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: Qwen/Qwen3-VL-Embedding-8B\n",
            "Model Name: Qwen/Qwen3-VL-Embedding-8B\n",
            "Pipeline Tag: image-to-text\n",
            "Tags: ['transformers', 'safetensors', 'qwen3_vl', 'image-to-text', 'multimodal embedding', 'base_model:Qwen/Qwen3-VL-8B-Instruct', 'base_model:finetune:Qwen/Qwen3-VL-8B-Instruct', 'license:apache-2.0', 'endpoints_compatible', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: Qwen/Qwen3-VL-Embedding-2B\n",
            "Model Name: Qwen/Qwen3-VL-Embedding-2B\n",
            "Pipeline Tag: image-to-text\n",
            "Tags: ['transformers', 'safetensors', 'qwen3_vl', 'image-to-text', 'multimodal embedding', 'base_model:Qwen/Qwen3-VL-2B-Instruct', 'base_model:finetune:Qwen/Qwen3-VL-2B-Instruct', 'license:apache-2.0', 'endpoints_compatible', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: nvidia/Alpamayo-R1-10B\n",
            "Model Name: nvidia/Alpamayo-R1-10B\n",
            "Pipeline Tag: robotics\n",
            "Tags: ['transformers', 'safetensors', 'alpamayo_r1', 'robotics', 'dataset:nvidia/PhysicalAI-Autonomous-Vehicles', 'dataset:nvidia/PhysicalAI-Autonomous-Vehicles-NuRec', 'arxiv:2511.00088', 'license:other', 'endpoints_compatible', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: Supertone/supertonic-2\n",
            "Model Name: Supertone/supertonic-2\n",
            "Pipeline Tag: text-to-speech\n",
            "Tags: ['supertonic', 'onnx', 'text-to-speech', 'speech-synthesis', 'tts', 'en', 'ko', 'es', 'pt', 'fr', 'license:openrail', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: MiniMaxAI/MiniMax-M2.1\n",
            "Model Name: MiniMaxAI/MiniMax-M2.1\n",
            "Pipeline Tag: text-generation\n",
            "Tags: ['transformers', 'safetensors', 'minimax_m2', 'text-generation', 'conversational', 'custom_code', 'arxiv:2509.06501', 'license:other', 'endpoints_compatible', 'fp8', 'deploy:azure', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: miromind-ai/MiroThinker-v1.5-30B\n",
            "Model Name: miromind-ai/MiroThinker-v1.5-30B\n",
            "Pipeline Tag: text-generation\n",
            "Tags: ['transformers', 'safetensors', 'qwen3_moe', 'text-generation', 'agent', 'open-source', 'miromind', 'deep-research', 'conversational', 'en', 'arxiv:2511.11793', 'base_model:Qwen/Qwen3-30B-A3B-Thinking-2507', 'base_model:finetune:Qwen/Qwen3-30B-A3B-Thinking-2507', 'license:mit', 'endpoints_compatible', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: miromind-ai/MiroThinker-v1.5-235B\n",
            "Model Name: miromind-ai/MiroThinker-v1.5-235B\n",
            "Pipeline Tag: text-generation\n",
            "Tags: ['transformers', 'safetensors', 'qwen3_moe', 'text-generation', 'agent', 'open-source', 'miromind', 'deep-research', 'conversational', 'en', 'arxiv:2511.11793', 'base_model:Qwen/Qwen3-235B-A22B-Thinking-2507', 'base_model:finetune:Qwen/Qwen3-235B-A22B-Thinking-2507', 'license:mit', 'endpoints_compatible', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: LiquidAI/LFM2.5-VL-1.6B\n",
            "Model Name: LiquidAI/LFM2.5-VL-1.6B\n",
            "Pipeline Tag: image-text-to-text\n",
            "Tags: ['transformers', 'safetensors', 'lfm2_vl', 'image-to-text', 'liquid', 'lfm2', 'lfm2-vl', 'edge', 'lfm2.5-vl', 'lfm2.5', 'image-text-to-text', 'conversational', 'en', 'ja', 'ko', 'fr', 'es', 'de', 'ar', 'zh', 'arxiv:2511.23404', 'base_model:LiquidAI/LFM2.5-1.2B-Base', 'base_model:finetune:LiquidAI/LFM2.5-1.2B-Base', 'license:other', 'endpoints_compatible', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: NousResearch/NousCoder-14B\n",
            "Model Name: NousResearch/NousCoder-14B\n",
            "Pipeline Tag: text-generation\n",
            "Tags: ['safetensors', 'qwen3', 'text-generation', 'conversational', 'dataset:livecodebench/code_generation_lite', 'dataset:agentica-org/DeepCoder-Preview-Dataset', 'dataset:NousResearch/lcb_test', 'dataset:NousResearch/RLVR_Coding_Problems', 'base_model:Qwen/Qwen3-14B', 'base_model:finetune:Qwen/Qwen3-14B', 'license:apache-2.0', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: tiiuae/Falcon-H1R-7B\n",
            "Model Name: tiiuae/Falcon-H1R-7B\n",
            "Pipeline Tag: text-generation\n",
            "Tags: ['transformers', 'safetensors', 'falcon_h1', 'text-generation', 'falcon-h1r', 'conversational', 'en', 'arxiv:2601.02346', 'base_model:tiiuae/Falcon-H1-7B-Base', 'base_model:finetune:tiiuae/Falcon-H1-7B-Base', 'license:other', 'endpoints_compatible', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: LiquidAI/LFM2-2.6B-Transcript\n",
            "Model Name: LiquidAI/LFM2-2.6B-Transcript\n",
            "Pipeline Tag: text-generation\n",
            "Tags: ['transformers', 'safetensors', 'lfm2', 'text-generation', 'liquid', 'edge', 'conversational', 'en', 'base_model:LiquidAI/LFM2-2.6B', 'base_model:finetune:LiquidAI/LFM2-2.6B', 'license:other', 'endpoints_compatible', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: Tongyi-MAI/Z-Image-Turbo\n",
            "Model Name: Tongyi-MAI/Z-Image-Turbo\n",
            "Pipeline Tag: text-to-image\n",
            "Tags: ['diffusers', 'safetensors', 'text-to-image', 'en', 'arxiv:2511.22699', 'arxiv:2511.22677', 'arxiv:2511.13649', 'license:apache-2.0', 'diffusers:ZImagePipeline', 'deploy:azure', 'region:us']\n",
            "--------------------------------------------------------------------------------\n",
            "Model ID: Qwen/Qwen-Image-2512\n",
            "Model Name: Qwen/Qwen-Image-2512\n",
            "Pipeline Tag: text-to-image\n",
            "Tags: ['diffusers', 'safetensors', 'text-to-image', 'en', 'zh', 'arxiv:2508.02324', 'license:apache-2.0', 'diffusers:QwenImagePipeline', 'deploy:azure', 'region:us']\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}