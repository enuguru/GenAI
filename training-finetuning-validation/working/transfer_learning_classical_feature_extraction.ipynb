{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Transfer Learning solution"
      ],
      "metadata": {
        "id": "psmSUoxoZD68"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! This program demonstrates a common workflow in deep learning for image classification using transfer learning with a pre-trained model on the CIFAR-10 dataset.\n",
        "\n",
        "High-level concept:\n",
        "\n",
        "The core idea is to leverage a powerful, pre-trained neural network (ResNet-18) that has already learned to recognize features from a very large dataset (ImageNet). Instead of training a new model from scratch, which requires a lot of data and computational resources, we adapt this pre-trained model for a new, but related, task (CIFAR-10 image classification).\n",
        "\n",
        "We 'freeze' most of the pre-trained model's layers, meaning their learned weights won't change during training. We then replace only the final classification layer with a new one tailored to the 10 classes of CIFAR-10. This new layer, along with any unfrozen parts of the original model (if any), is then trained on the CIFAR-10 dataset. This approach is called transfer learning, and it's very effective for tasks where you have limited data but a relevant pre-trained model exists.\n",
        "\n",
        "What the program is doing step-by-step:\n",
        "\n",
        "Setup and Data Preparation:\n",
        "\n",
        "Installs torch, torchvision, and torchaudio libraries.\n",
        "Imports necessary modules from PyTorch for building and training neural networks.\n",
        "Defines image transforms to resize images and convert them to PyTorch tensors.\n",
        "Downloads and loads the CIFAR-10 dataset, splitting it into training and testing sets, and applies the defined transformations.\n",
        "Creates DataLoader objects to efficiently load data in batches during training and evaluation.\n",
        "Model Loading and Modification (Transfer Learning):\n",
        "\n",
        "Loads a pre-trained ResNet-18 model (a popular convolutional neural network architecture).\n",
        "Freezes all the layers of the loaded ResNet-18, preventing their weights from being updated during training.\n",
        "Replaces the model's final fully connected (fc) layer (which originally classified 1000 ImageNet classes) with a new linear layer that outputs 10 classes, matching CIFAR-10.\n",
        "Moves the model to the appropriate device (cuda for GPU if available, otherwise cpu).\n",
        "Training Setup:\n",
        "\n",
        "Defines the CrossEntropyLoss function, which is commonly used for multi-class classification problems.\n",
        "Sets up the Adam optimizer, which will be used to update the weights of the newly added classification layer (since other layers are frozen).\n",
        "Training Loop:\n",
        "\n",
        "Iterates for a specified number of epochs (in this case, 2).\n",
        "In each epoch, it goes through the train_loader batch by batch:\n",
        "Moves images and labels to the device.\n",
        "Performs a forward pass (makes predictions).\n",
        "Calculates the loss between predictions and actual labels.\n",
        "Performs a backward pass (calculates gradients).\n",
        "Updates the model's parameters (only the new fc layer's weights).\n",
        "Prints the average training loss for each epoch.\n",
        "Evaluation:\n",
        "\n",
        "Sets the model to evaluation mode (model.eval()).\n",
        "Disables gradient calculations (torch.no_grad()) to save memory and speed up computation.\n",
        "Iterates through the test_loader batch by batch:\n",
        "Makes predictions on the test data.\n",
        "Compares predictions to actual labels to count correct classifications.\n",
        "Calculates and prints the final accuracy of the model on the test dataset."
      ],
      "metadata": {
        "id": "kb2SD_2bZFIb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RYb0Kp7bUePl"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "HZRd5CKaUhux"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "f8Uj1KRgUmjj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_data  = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_data, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1BlUxssUpGa",
        "outputId": "4f5b0c03-2c8e-4c37-da2a-2c7d6fca661f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [03:08<00:00, 907kB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "\n",
        "# Freeze all layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the final fully connected layer\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 10)  # CIFAR-10 has 10 classes\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXzyp7nsUsOk",
        "outputId": "e9f4f67a-63de-4b37-813f-ebe1c8505334"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 226MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "EJO4L7pPU0aS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] Loss: {running_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl_xDEQtVHaB",
        "outputId": "4346b4a2-22c4-4f95-bc41-b490611d47ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2] Loss: 0.8367\n",
            "Epoch [2/2] Loss: 0.6221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = outputs.max(1)\n",
        "\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "print(f\"Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gMZinVkVNNw",
        "outputId": "7405cc09-8f83-4d89-e874-4bab4c4ffceb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 79.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HgzOCc7RYuy9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}