{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "#api_key = \"\""
      ],
      "metadata": {
        "id": "YaLIIuJGgoPK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CiO-NBT-Yqm",
        "outputId": "4699e7f1-7845-4a00-9632-6f5c4e11aec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple AI agent. Type 'quit' to exit.\n",
            "\n",
            "You: Who is the chief minister of Assam\n",
            "Agent: The Chief Minister of Assam is Himanta Biswa Sarma (Bharatiya Janata Party). He has served as CM since 10 May 2021.\n",
            "\n",
            "You: exit\n",
            "Agent: Goodbye! ðŸ‘‹\n"
          ]
        }
      ],
      "source": [
        "# Create a client (reads OPENAI_API_KEY from env)\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a helpful AI agent.\n",
        "- Answer clearly and concisely.\n",
        "- Ask for clarification only when truly needed.\n",
        "\"\"\"\n",
        "\n",
        "def run_agent():\n",
        "    print(\"Simple AI agent. Type 'quit' to exit.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.strip().lower() in {\"quit\", \"exit\"}:\n",
        "            print(\"Agent: Goodbye! ðŸ‘‹\")\n",
        "            break\n",
        "\n",
        "        # Call the LLM via Responses API\n",
        "        response = client.responses.create(\n",
        "            model=\"gpt-5-mini\",   # or gpt-4.1-mini, etc.\n",
        "            input=[\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": user_input},\n",
        "            ],\n",
        "        )\n",
        "\n",
        "        # Convenient helper: output_text aggregates all text output\n",
        "        agent_reply = response.output_text\n",
        "        print(f\"Agent: {agent_reply}\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_agent()\n"
      ]
    }
  ]
}